This project demonstrates the use of K-Nearest Neighbors (KNN) for classifying the Iris dataset.
It includes feature normalization, model training with different K values, accuracy & confusion matrix evaluation, and visualization of decision boundaries using PCA for dimensionality reduction.
The code compares multiple K values to observe accuracy changes and plots results for the best-performing model.
All visualizations are created using Matplotlib for better interpretability.
This serves as a beginner-friendly example of classification and data visualization in Python.

